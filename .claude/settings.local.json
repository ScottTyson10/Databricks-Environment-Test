{
  "permissions": {
    "allow": [
      "Bash(make:*)",
      "Bash(python:*)",
      "Bash(CREATE_TEST_TABLES=true make test-integration-table-comments)",
      "Bash(CREATE_TEST_TABLES=true make test-integration-comment-length)",
      "Bash(cp:*)",
      "Bash(pytest:*)",
      "Bash(rm:*)",
      "Bash(mkdir:*)",
      "Bash(mv:*)",
      "WebSearch",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegrationEnvironment::test_databricks_connection -v --tb=long)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegrationEnvironment::test_databricks_connection -v)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegration::test_end_to_end_placeholder_detection_validation -v --tb=short)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegration::test_end_to_end_placeholder_detection_validation -v --tb=long -s)",
      "Bash(CREATE_TEST_TABLES=true python debug_test.py)",
      "Bash(CREATE_TEST_TABLES=true python debug_minimal.py)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegration::test_end_to_end_placeholder_detection_validation -v --tb=short -s)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegration::test_end_to_end_placeholder_detection_validation --capture=no)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py::TestPlaceholderDetectionIntegration::test_end_to_end_placeholder_detection_validation -v)",
      "Bash(grep:*)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_placeholder_detection_integration.py -v --tb=short)",
      "Bash(tree:*)",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom databricks.sdk import WorkspaceClient\nfrom dotenv import load_dotenv\nfrom tests.fixtures.table_factory import TABLE_SPECS_CRITICAL_COLUMNS\nfrom tests.validators.documentation import DocumentationValidator\nfrom tests.utils.discovery_engine import create_integration_discovery\n\nload_dotenv()\n\nclient = WorkspaceClient()\ndiscovery = create_integration_discovery(client)\nvalidator = DocumentationValidator()\n\n# Find the no_critical table\ntables = discovery.discover_tables()\nfor table in tables:\n    if ''critical_test_no_critical'' in table.table:\n        print(f''Table: {table.table}'')\n        print(f''Columns: {table.columns}'')\n        print(f''Critical patterns check:'')\n        for col in table.columns:\n            print(f''  {col.name} (type: {col.type_text}, comment: {col.comment!r})'')\n            # Check if this column matches any critical pattern\n            col_name_lower = col.name.lower()\n            critical_patterns = [''id'', ''key'', ''uuid'', ''email'', ''name'', ''phone'', ''address'', ''ssn'', ''dob'', ''birth'',\n                               ''account'', ''credit'', ''card'', ''bank'', ''salary'', ''payment'',\n                               ''password'', ''token'', ''secret'', ''created'', ''modified'', ''updated'', ''deleted'', ''user'']\n            matches = [pattern for pattern in critical_patterns if pattern in col_name_lower]\n            print(f''    Matches critical patterns: {matches}'')\n        print(f''Undocumented critical: {validator.get_undocumented_critical_columns(table)}'')\n        print(f''All documented: {validator.has_all_critical_columns_documented(table)}'')\n        break\n\")",
      "mcp__ide__executeCode",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom databricks.sdk import WorkspaceClient\nfrom dotenv import load_dotenv\nfrom tests.fixtures.table_factory import TABLE_SPECS_CRITICAL_COLUMNS\nfrom tests.validators.documentation import DocumentationValidator\nfrom tests.utils.discovery_engine import create_integration_discovery\n\nload_dotenv()\n\nclient = WorkspaceClient()\ndiscovery = create_integration_discovery(client)\nvalidator = DocumentationValidator()\n\n# Find the no_critical table\ntables = discovery.discover_tables()\nfor table in tables:\n    if ''critical_test_no_critical'' in table.table:\n        print(f''Table: {table.table}'')\n        print(f''Columns: {table.columns}'')\n        print(f''Critical patterns check:'')\n        for col in table.columns:\n            print(f''  {col.name} (type: {col.type_text}, comment: {col.comment!r})'')\n            # Check if this column matches any critical pattern\n            col_name_lower = col.name.lower()\n            critical_patterns = [''id'', ''key'', ''uuid'', ''email'', ''name'', ''phone'', ''address'', ''ssn'', ''dob'', ''birth'',\n                               ''account'', ''credit'', ''card'', ''bank'', ''salary'', ''payment'',\n                               ''password'', ''token'', ''secret'', ''created'', ''modified'', ''updated'', ''deleted'', ''user'']\n            matches = [pattern for pattern in critical_patterns if pattern in col_name_lower]\n            print(f''    Matches critical patterns: {matches}'')\n        print(f''Undocumented critical: {validator.get_undocumented_critical_columns(table)}'')\n        print(f''All documented: {validator.has_all_critical_columns_documented(table)}'')\n        break\n\")",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom tests.fixtures.table_factory import TABLE_SPECS_CRITICAL_COLUMNS\nprint(''Table spec no_critical_columns:'')\nspec = TABLE_SPECS_CRITICAL_COLUMNS[''no_critical_columns'']\nprint(f''  name: {spec.name}'')\nprint(f''  columns: {spec.columns}'')\nprint(f''  expected_pass: {spec.expected_pass}'')\n\n# Check pattern matching\ncritical_patterns = [''id'', ''key'', ''uuid'', ''email'', ''name'', ''phone'', ''address'', ''ssn'', ''dob'', ''birth'',\n                   ''account'', ''credit'', ''card'', ''bank'', ''salary'', ''payment'',\n                   ''password'', ''token'', ''secret'', ''created'', ''modified'', ''updated'', ''deleted'', ''user'']\n                   \nfor col_name, col_type, col_comment in spec.columns:\n    col_name_lower = col_name.lower()\n    matches = [pattern for pattern in critical_patterns if pattern in col_name_lower]\n    print(f''  Column {col_name}: matches {matches}'')\n\")",
      "Bash(CREATE_TEST_TABLES=true make test-integration)",
      "Bash(pkill:*)",
      "Bash(CREATE_TEST_TABLES=true pytest tests/integration/documentation/test_comment_length_integration.py::TestCommentLengthIntegration::test_end_to_end_comment_length_validation -v)",
      "Bash(CREATE_TEST_TABLES=true make test-scenario SCENARIO=critical-columns LAYER=integration)",
      "Bash(CREATE_TEST_TABLES=true make test-scenario SCENARIO=column-coverage-threshold LAYER=integration)",
      "Bash(find:*)",
      "Bash(ruff check:*)",
      "Bash(mypy:*)",
      "WebFetch(domain:docs.databricks.com)",
      "WebFetch(domain:databricks-sdk-py.readthedocs.io)",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom databricks.sdk import WorkspaceClient\nfrom dotenv import load_dotenv\nfrom tests.utils.discovery_engine import create_integration_discovery\n\nload_dotenv()\n\nclient = WorkspaceClient()\ndiscovery = create_integration_discovery(client)\n\n# Find a few tables and inspect their properties for delta auto-optimization\ntables = discovery.discover_tables()\nprint(''=== Delta Auto-Optimization Property Investigation ==='')\nprint(f''Analyzing {len(tables)} tables...'')\n\ndelta_properties_found = []\nfor table in tables[:10]:  # Check first 10 tables\n    if table.properties:\n        # Look for delta auto-optimization properties\n        auto_opt_props = {k: v for k, v in table.properties.items() \n                         if ''autoOptimize'' in k or ''optimizeWrite'' in k or ''autoCompact'' in k}\n        if auto_opt_props:\n            delta_properties_found.append({\n                ''table'': table.full_name,\n                ''properties'': auto_opt_props\n            })\n            \n# Report findings\nif delta_properties_found:\n    print(f''Found {len(delta_properties_found)} tables with delta auto-optimization properties:'')\n    for item in delta_properties_found:\n        print(f''  Table: {item[\"\"table\"\"]}'')\n        for prop, value in item[''properties''].items():\n            print(f''    {prop}: {value}'')\n        print()\nelse:\n    print(''No delta auto-optimization properties found in sampled tables.'')\n    print(''Let\\''s check what properties are commonly available:'')\n    all_props = set()\n    for table in tables[:5]:\n        if table.properties:\n            all_props.update(table.properties.keys())\n    print(f''Common property keys found: {sorted(list(all_props))}'')\n\")",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom databricks.sdk import WorkspaceClient\nfrom dotenv import load_dotenv\nimport time\n\nload_dotenv()\nclient = WorkspaceClient()\n\n# Create a small test table with delta auto-optimization to see property names\ntable_name = ''pytest_test_data.delta_optimization_feasibility_test''\nprint(f''Creating feasibility test table: {table_name}'')\n\ntry:\n    # Drop if exists\n    try:\n        client.tables.delete(table_name)\n        print(''Dropped existing test table'')\n    except Exception:\n        pass\n    \n    # Create table with delta auto-optimization properties\n    sql_commands = [\n        f''''''\n        CREATE TABLE {table_name} (\n            test_id INT,\n            test_name STRING\n        ) USING DELTA\n        TBLPROPERTIES (\n            ''delta.autoOptimize.optimizeWrite'' = ''true'',\n            ''delta.autoOptimize.autoCompact'' = ''true''\n        )\n        '''''',\n        f''INSERT INTO {table_name} VALUES (1, \"\"test_data\"\")''\n    ]\n    \n    for sql in sql_commands:\n        print(f''Executing: {sql.strip()[:50]}...'')\n        statement_response = client.statement_execution.execute_statement(\n            warehouse_id=client.config.warehouse_id,\n            statement=sql,\n            wait_timeout=''30s''\n        )\n        if statement_response.status.state.name != ''SUCCEEDED'':\n            raise Exception(f''SQL failed: {statement_response.status.error}'')\n    \n    # Now check the table properties \n    print(''\\nFetching table information...'')\n    time.sleep(2)  # Allow time for metadata to update\n    \n    table_info = client.tables.get(table_name)\n    \n    print(f''\\nTable properties for {table_name}:'')\n    if hasattr(table_info, ''properties'') and table_info.properties:\n        for prop, value in sorted(table_info.properties.items()):\n            print(f''  {prop}: {value}'')\n            \n        # Specifically check for auto-optimization properties\n        auto_opt_props = {k: v for k, v in table_info.properties.items() \n                         if ''autoOptimize'' in k or ''optimizeWrite'' in k or ''autoCompact'' in k}\n        if auto_opt_props:\n            print(f''\\n*** DELTA AUTO-OPTIMIZATION PROPERTIES FOUND: ***'')\n            for prop, value in auto_opt_props.items():\n                print(f''  {prop}: {value} (type: {type(value).__name__})'')\n        else:\n            print(''\\nNo delta auto-optimization properties found in table metadata'')\n    else:\n        print(''No properties found'')\n        \n    # Clean up\n    print(''\\nCleaning up test table...'')\n    client.tables.delete(table_name)\n    print(''Test completed successfully'')\n    \nexcept Exception as e:\n    print(f''Error during feasibility test: {e}'')\n    # Try cleanup anyway\n    try:\n        client.tables.delete(table_name)\n    except:\n        pass\n\")",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom databricks.sdk import WorkspaceClient\nfrom dotenv import load_dotenv\nimport time\n\nload_dotenv()\nclient = WorkspaceClient()\n\n# Get the current catalog and schema\ncatalogs = list(client.catalogs.list())\nif catalogs:\n    catalog_name = catalogs[0].name\n    print(f''Using catalog: {catalog_name}'')\nelse:\n    print(''No catalogs found'')\n    exit(1)\n\n# Create a small test table with delta auto-optimization to see property names\ntable_name = f''{catalog_name}.pytest_test_data.delta_opt_test''\nprint(f''Creating feasibility test table: {table_name}'')\n\ntry:\n    # Create table with delta auto-optimization properties\n    sql_commands = [\n        f''''''\n        CREATE TABLE IF NOT EXISTS {table_name} (\n            test_id INT,\n            test_name STRING\n        ) USING DELTA\n        TBLPROPERTIES (\n            \\''delta.autoOptimize.optimizeWrite\\'' = \\''true\\'',\n            \\''delta.autoOptimize.autoCompact\\'' = \\''true\\''\n        )\n        '''''',\n        f''INSERT INTO {table_name} VALUES (1, \"\"test_data\"\")''\n    ]\n    \n    for sql in sql_commands:\n        print(f''Executing: {sql.strip()[:80]}...'')\n        statement_response = client.statement_execution.execute_statement(\n            warehouse_id=client.config.warehouse_id,\n            statement=sql,\n            wait_timeout=''30s''\n        )\n        if statement_response.status.state.name != ''SUCCEEDED'':\n            raise Exception(f''SQL failed: {statement_response.status.error}'')\n    \n    # Now check the table properties using our discovery engine\n    print(''\\nUsing discovery engine to check properties...'')\n    from tests.utils.discovery_engine import create_integration_discovery\n    \n    discovery = create_integration_discovery(client)\n    tables = discovery.discover_tables()\n    \n    # Find our test table\n    test_table = None\n    for table in tables:\n        if table.table == ''delta_opt_test'':\n            test_table = table\n            break\n            \n    if test_table and test_table.properties:\n        print(f''\\nTable properties for {test_table.full_name}:'')\n        for prop, value in sorted(test_table.properties.items()):\n            print(f''  {prop}: {value}'')\n            \n        # Specifically check for auto-optimization properties\n        auto_opt_props = {k: v for k, v in test_table.properties.items() \n                         if ''autoOptimize'' in k or ''optimizeWrite'' in k or ''autoCompact'' in k}\n        if auto_opt_props:\n            print(f''\\n*** DELTA AUTO-OPTIMIZATION PROPERTIES FOUND: ***'')\n            for prop, value in auto_opt_props.items():\n                print(f''  {prop}: {value} (type: {type(value).__name__})'')\n        else:\n            print(''\\nNo delta auto-optimization properties found in discovered table'')\n    else:\n        print(''Test table not found in discovery results or no properties available'')\n        \n    # Clean up\n    print(''\\nCleaning up test table...'')\n    cleanup_sql = f''DROP TABLE IF EXISTS {table_name}''\n    client.statement_execution.execute_statement(\n        warehouse_id=client.config.warehouse_id,\n        statement=cleanup_sql,\n        wait_timeout=''30s''\n    )\n    print(''Test completed successfully'')\n    \nexcept Exception as e:\n    print(f''Error during feasibility test: {e}'')\n    # Try cleanup anyway\n    try:\n        cleanup_sql = f''DROP TABLE IF EXISTS {table_name}''\n        client.statement_execution.execute_statement(\n            warehouse_id=client.config.warehouse_id,\n            statement=cleanup_sql,\n            wait_timeout=''30s''\n        )\n    except:\n        pass\n\")",
      "Bash(CREATE_TEST_TABLES=true python -c \"\nfrom databricks.sdk import WorkspaceClient\nfrom dotenv import load_dotenv\nimport time\n\nload_dotenv()\nclient = WorkspaceClient()\n\n# Use workspace catalog specifically\ntable_name = ''workspace.pytest_test_data.delta_opt_test''\nprint(f''Creating feasibility test table: {table_name}'')\n\ntry:\n    # Create table with delta auto-optimization properties\n    sql_commands = [\n        f''''''\n        CREATE TABLE IF NOT EXISTS {table_name} (\n            test_id INT,\n            test_name STRING\n        ) USING DELTA\n        TBLPROPERTIES (\n            \\''delta.autoOptimize.optimizeWrite\\'' = \\''true\\'',\n            \\''delta.autoOptimize.autoCompact\\'' = \\''true\\''\n        )\n        '''''',\n        f''INSERT INTO {table_name} VALUES (1, \"\"test_data\"\")''\n    ]\n    \n    for sql in sql_commands:\n        print(f''Executing: {sql.strip()[:80]}...'')\n        statement_response = client.statement_execution.execute_statement(\n            warehouse_id=client.config.warehouse_id,\n            statement=sql,\n            wait_timeout=''30s''\n        )\n        if statement_response.status.state.name != ''SUCCEEDED'':\n            raise Exception(f''SQL failed: {statement_response.status.error}'')\n    \n    print(''Table created successfully!'')\n    \n    # Now check the table properties using our discovery engine\n    print(''\\nUsing discovery engine to check properties...'')\n    from tests.utils.discovery_engine import create_integration_discovery\n    \n    discovery = create_integration_discovery(client)\n    tables = discovery.discover_tables()\n    \n    # Find our test table\n    test_table = None\n    for table in tables:\n        if table.table == ''delta_opt_test'' and table.catalog == ''workspace'':\n            test_table = table\n            break\n            \n    if test_table:\n        print(f''\\nFound test table: {test_table.full_name}'')\n        if test_table.properties:\n            print(''\\nAll table properties:'')\n            for prop, value in sorted(test_table.properties.items()):\n                print(f''  {prop}: {value}'')\n                \n            # Specifically check for auto-optimization properties\n            auto_opt_props = {k: v for k, v in test_table.properties.items() \n                             if ''autoOptimize'' in k or ''optimizeWrite'' in k or ''autoCompact'' in k or ''delta.auto'' in k.lower()}\n            if auto_opt_props:\n                print(f''\\n*** DELTA AUTO-OPTIMIZATION PROPERTIES FOUND: ***'')\n                for prop, value in auto_opt_props.items():\n                    print(f''  {prop}: {value} (type: {type(value).__name__})'')\n            else:\n                print(''\\nNo delta auto-optimization properties found in discovered table'')\n                print(''Checking for any delta properties...'')\n                delta_props = {k: v for k, v in test_table.properties.items() if ''delta'' in k.lower()}\n                for prop, value in delta_props.items():\n                    print(f''  {prop}: {value}'')\n        else:\n            print(''No properties found on test table'')\n    else:\n        print(''Test table not found in discovery results'')\n        print(f''Available tables in pytest_test_data: {[t.table for t in tables if t.schema == \"\"pytest_test_data\"\"]}'')\n        \n    # Clean up\n    print(''\\nCleaning up test table...'')\n    cleanup_sql = f''DROP TABLE IF EXISTS {table_name}''\n    client.statement_execution.execute_statement(\n        warehouse_id=client.config.warehouse_id,\n        statement=cleanup_sql,\n        wait_timeout=''30s''\n    )\n    print(''Test completed successfully'')\n    \nexcept Exception as e:\n    print(f''Error during feasibility test: {e}'')\n    # Try cleanup anyway\n    try:\n        cleanup_sql = f''DROP TABLE IF EXISTS {table_name}''\n        client.statement_execution.execute_statement(\n            warehouse_id=client.config.warehouse_id,\n            statement=cleanup_sql,\n            wait_timeout=''30s''\n        )\n    except Exception as cleanup_error:\n        print(f''Cleanup also failed: {cleanup_error}'')\n\")",
      "Bash(CREATE_TEST_TABLES=true make test-scenario SCENARIO=delta-auto-optimization LAYER=integration)"
    ],
    "deny": [],
    "ask": [],
    "additionalDirectories": [
      "/private/tmp"
    ]
  }
}